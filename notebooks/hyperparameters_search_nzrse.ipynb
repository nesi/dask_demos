{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameters tuning on HPC - NZ RSE 2020\n",
    "\n",
    "This demo illustrates one simple way multiple ways to adapt a random search\n",
    "strategy for hyper-parameters tuning to use HPC for the many parallel\n",
    "computations involved.\n",
    "\n",
    "In this example, we will rely on [Dask](https://dask.org) to do the heavy lifting,\n",
    "distributing the parallel operations on SLURM jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import joblib\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask_ml.model_selection import HyperbandSearchCV\n",
    "\n",
    "import torch\n",
    "import skorch\n",
    "from src.torch_models import SimpleCNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load MNIST data from [OpenML](https://www.openml.org/d/554)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True)\n",
    "X = X / 255.0\n",
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO display sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep the example fast, let's use only a subset of the whole data set as\n",
    "train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, train_size=5000, test_size=10000, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a simple multi-layer perceptron neural net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.8 s, sys: 25.3 s, total: 52.1 s\n",
      "Wall time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlp = MLPClassifier(random_state=42).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MLP test accuracy is 93.77%.\n"
     ]
    }
   ],
   "source": [
    "y_pred = mlp.predict(X_test)\n",
    "mlp_acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Baseline MLP test accuracy is {mlp_acc * 100:.2f}%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune hyper-parameters using a random search strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {\n",
    "    \"hidden_layer_sizes\": st.randint(50, 200),\n",
    "    \"alpha\": st.loguniform(1e-5, 1e-2),\n",
    "    \"learning_rate_init\": st.loguniform(1e-4, 1e-1),\n",
    "}\n",
    "mlp_tuned = RandomizedSearchCV(\n",
    "    MLPClassifier(random_state=42), param_space, n_iter=10, random_state=42, verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a Dask cluster using SLURM jobs as workers.\n",
    "\n",
    "There are a couple of things we need to configure here:\n",
    "\n",
    "- disabling the mechanism to write on disk when workers run out of memory,\n",
    "- memory, CPUs, maximum time and number of workers per SLURM job,\n",
    "- dask folders for log files and workers data.\n",
    "\n",
    "All of these options can be set in configuration files, see [Dask configuration](https://docs.dask.org/en/latest/configuration.html)\n",
    "and [Dask jobqueue configuration](https://jobqueue.dask.org/en/latest/configuration-setup.html)\n",
    "for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.config.set(\n",
    "    {\n",
    "        \"distributed.worker.memory.target\": False,  # avoid spilling to disk\n",
    "        \"distributed.worker.memory.spill\": False,  # avoid spilling to disk\n",
    "    }\n",
    ")\n",
    "cluster = SLURMCluster(\n",
    "    cores=10,\n",
    "    processes=2,\n",
    "    memory=\"8GiB\",\n",
    "    walltime=\"0-00:30\",\n",
    "    log_directory=\"../dask/logs\",  # folder for SLURM logs for each worker\n",
    "    local_directory=\"../dask\",  # folder for workers data\n",
    "    queue=\"bigmem\",\n",
    ")\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spawn 20 workers and connect a client to be able use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(n=20)\n",
    "client.wait_for_workers(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn uses [Joblib](https://joblib.readthedocs.io) to parallelize\n",
    "computations of many operations, including the randomized search on\n",
    "hyper-parameters. If we configure Joblib to use Dask as a backend,\n",
    "computations will be automatically scheduled and distributed on nodes of the\n",
    "HPC platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend DaskDistributedBackend with 20 concurrent workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.4 s, sys: 8.09 s, total: 22.5 s\n",
      "Wall time: 3min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with joblib.parallel_backend(\"dask\", scatter=[X_train, y_train]):\n",
    "    mlp_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enjoy an optimized model :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned MLP test accuracy is 95.06%.\n"
     ]
    }
   ],
   "source": [
    "y_pred_tuned = mlp_tuned.predict(X_test)\n",
    "mlp_tuned_acc = accuracy_score(y_test, y_pred_tuned)\n",
    "print(f\"Tuned MLP test accuracy is {mlp_tuned_acc * 100:.2f}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters:\n",
      "{\n",
      "    \"alpha\": 0.00010025956902289563,\n",
      "    \"hidden_layer_sizes\": 153,\n",
      "    \"learning_rate_init\": 0.013311216080736881\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best hyper-parameters:\\n{json.dumps(mlp_tuned.best_params_, indent=4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first approach requires very little changes but is far from optimal from\n",
    "a ressource usage perspective. The [Dask-ML](https://ml.dask.org/) package\n",
    "implements a more advanced algorithm, [Hyperband](https://arxiv.org/abs/1603.06560),\n",
    "designed to better use a finite bugdet, using early stopping of bad\n",
    "configurations. It relies on Scikit-learn API, assuming the estimator\n",
    "implements the `partial_fit` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_hyper = HyperbandSearchCV(\n",
    "    MLPClassifier(random_state=42),\n",
    "    param_space,\n",
    "    max_iter=200,\n",
    "    aggressiveness=4,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.59 s, sys: 749 ms, total: 7.34 s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = mlp_hyper.fit(X_train, y_train, classes=np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP (Hyperband) test accuracy is 95.10%.\n"
     ]
    }
   ],
   "source": [
    "y_pred_hyper = mlp_hyper.predict(X_test)\n",
    "mlp_hyper_acc = accuracy_score(y_test, y_pred_hyper)\n",
    "print(f\"MLP (Hyperband) test accuracy is {mlp_hyper_acc * 100:.2f}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters:\n",
      "{\n",
      "    \"alpha\": 2.3033838055846953e-05,\n",
      "    \"hidden_layer_sizes\": 182,\n",
      "    \"learning_rate_init\": 0.009713117934574873\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best hyper-parameters:\\n{json.dumps(mlp_hyper.best_params_, indent=4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we want to try some deep learning models trained with GPUs, we need to\n",
    "start a new Dask cluster, requesting the right resources. First let's stop the\n",
    "current cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then start a new cluster, explicitly asking for GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(\n",
    "    cores=4,\n",
    "    processes=1,\n",
    "    memory=\"4GiB\",\n",
    "    walltime=\"0-00:30\",\n",
    "    log_directory=\"../dask/logs\",\n",
    "    local_directory=\"../dask\",\n",
    "    job_extra=[\"--gres gpu:1\"],  # passed to job script to request a GPU\n",
    "    queue=\"gpu\",  # use the GPU partition\n",
    ")\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use an adaptive scaling strategy, asking Dask scheduler to start at\n",
    "least one worker and letting it spawning on the fly more if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.adapt(minimum=1, maximum=4)\n",
    "client.wait_for_workers(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "For the deep learning part, let's use a simple convolutional neural network\n",
    "implemented using [Pytorch](https://pytorch.org/). We make use of [Skorch](https://github.com/skorch-dev/skorch)\n",
    "to make it in a Scikit-learn compatible estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(device):\n",
    "    torch.manual_seed(0)\n",
    "    return skorch.NeuralNetClassifier(\n",
    "        module=SimpleCNN,\n",
    "        module__input_dims=(28, 28),\n",
    "        module__output_dim=len(np.unique(y)),\n",
    "        module__n_chans=32,\n",
    "        module__hidden_dim=100,\n",
    "        module__dropout=0.5,\n",
    "        optimizer=torch.optim.Adam,\n",
    "        optimizer__lr=1e-3,\n",
    "        device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training the model, we will compare timing on CPU and GPU. This will\n",
    "also illustrate another aspect of the Dask API: direct submission of tasks\n",
    "on the cluster.\n",
    "\n",
    "We first dispatch training data on the cluster using `client.scatter`, to save\n",
    "some bandwidth later. Here `X_train_future` is a **future** object, no yet\n",
    "computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Future: ndarray</b> <font color=\"gray\">status: </font><font color=\"black\">finished</font>, <font color=\"gray\">type: </font>numpy.ndarray, <font color=\"gray\">key: </font>ndarray-9f1886153b6feaa3490197e81e27b353"
      ],
      "text/plain": [
       "<Future: finished, type: numpy.ndarray, key: ndarray-9f1886153b6feaa3490197e81e27b353>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_future = client.scatter(X_train.astype(np.float32))\n",
    "X_train_future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's instantiate the CPU version of the model. `client.submit` send\n",
    "the computation, here `model.fit`, on a worker of the cluster and returns a\n",
    "future object. This is a non-blocking call. To wait and get the result, we can\n",
    "use the `result` method of the future object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_torch = build_model(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 343 ms, sys: 71.3 ms, total: 414 ms\n",
      "Wall time: 22.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlp_torch_future = client.submit(mlp_torch.fit, X_train_future, y_train)\n",
    "mlp_torch = mlp_torch_future.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's try the GPU version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_torch = build_model(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 154 ms, sys: 33.4 ms, total: 188 ms\n",
      "Wall time: 9.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    mlp_torch_future = client.submit(mlp_torch.fit, X_train_future, y_train)\n",
    "    mlp_torch = mlp_torch_future.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to Skorch, our model is compatible with Scikit-learn API, and thus can\n",
    "be used with Dask-ML meta-estimators. Hence we will use Hyberband to search\n",
    "for the best hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {\n",
    "    \"module__n_chans\": st.randint(10, 64),\n",
    "    \"module__hidden_dim\": st.randint(50, 200),\n",
    "    \"module__dropout\": st.uniform(),\n",
    "    \"optimizer__lr\": st.loguniform(1e-4, 1e-1),\n",
    "}\n",
    "mlp_torch = HyperbandSearchCV(\n",
    "    build_model(\"cuda\"), param_space, max_iter=20, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.01 s, sys: 417 ms, total: 2.42 s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    mlp_torch.fit(X_train.astype(np.float32), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN (PyTorch & Hyperband) test accuracy is 97.45%.\n"
     ]
    }
   ],
   "source": [
    "y_pred_torch = mlp_torch.predict(X_test.astype(np.float32))\n",
    "mlp_torch_acc = accuracy_score(y_test, y_pred_torch)\n",
    "print(f\"CNN (PyTorch & Hyperband) test accuracy is {mlp_torch_acc * 100:.2f}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters:\n",
      "{\n",
      "    \"module__dropout\": 0.5986584841970366,\n",
      "    \"module__hidden_dim\": 152,\n",
      "    \"module__n_chans\": 28,\n",
      "    \"optimizer__lr\": 0.0001994916615063393\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best hyper-parameters:\\n{json.dumps(mlp_torch.best_params_, indent=4)}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "hpc_for_datascience_demos",
   "language": "python",
   "name": "hpc_for_datascience_demos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
