{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameters tuning on HPC (basic)\n",
    "\n",
    "This demo illustrates one simple way to adapt a grid search strategy for\n",
    "hyper-parameters tuning to use HPC for the many parallel computations involved.\n",
    "\n",
    "In this example, I will rely on [Dask](https://dask.org) to do the heavy lifting,\n",
    "distributing the parallel operations on SLURM jobs. We'll see how it can be used\n",
    "as a backend for [Scikit-Learn](https://scikit-learn.org) estimators, with very\n",
    "little changes compared to a vanilla grid search.\n",
    "\n",
    "TODO link to other notebook for advanced stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import joblib\n",
    "from dask.distributed import Client\n",
    "from dask_jobqueue import SLURMCluster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load MNIST data from [OpenML](https://www.openml.org/d/554)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True)\n",
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, train_size=5000, test_size=10000, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a simple multi-layer perceptron neural net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitting took 13.47s.\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "mlp = MLPClassifier().fit(X_train, y_train)\n",
    "elapsed = time.perf_counter() - start\n",
    "print(f\"Model fitting took {elapsed:0.2f}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MLP test accuracy is 93.86%.\n"
     ]
    }
   ],
   "source": [
    "y_pred = mlp.predict(X_test)\n",
    "mlp_acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Baseline MLP test accuracy is {mlp_acc * 100:.2f}%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune hyper-parameters using a random search strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"hidden_layer_sizes\": [(50,), (100,), (200,)],\n",
    "    \"alpha\": np.logspace(-5, -3, 3),\n",
    "    \"learning_rate_init\": np.logspace(-4, -2, 3),\n",
    "}\n",
    "mlp_tuned = GridSearchCV(MLPClassifier(), param_grid, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a Dask cluster (see notes in README.md about additional configuration files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(cores=10, processes=2, memory=\"8GiB\", walltime=\"0-00:30\")\n",
    "cluster.scale(n=10)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn uses [Joblib](https://joblib.readthedocs.io) to parallelize\n",
    "computations of many operations, including the randomized search on hyper-parameters.\n",
    "If we configure Joblib to use Dask as a backend, computations will be automatically\n",
    "scheduled and distributed on nodes of the HPC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend DaskDistributedBackend with 20 concurrent workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 135 out of 135 | elapsed:  3.2min finished\n"
     ]
    }
   ],
   "source": [
    "with joblib.parallel_backend(\"dask\", wait_for_workers_timeout=600):\n",
    "    start = time.perf_counter()\n",
    "    mlp_tuned.fit(X_train, y_train)\n",
    "    elapsed = time.perf_counter() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitting took 199.47s (1.48s per model fit).\n"
     ]
    }
   ],
   "source": [
    "n_jobs = len(mlp_tuned.cv_results_[\"params\"]) * mlp_tuned.n_splits_\n",
    "print(f\"Model fitting took {elapsed:0.2f}s ({elapsed / n_jobs:0.2f}s per model fit).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enjoy an optimized model :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned MLP test accuracy is 95.17%.\n"
     ]
    }
   ],
   "source": [
    "y_pred_tuned = mlp_tuned.predict(X_test)\n",
    "mlp_tuned_acc = accuracy_score(y_test, y_pred_tuned)\n",
    "print(f\"Tuned MLP test accuracy is {mlp_tuned_acc * 100:.2f}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'alpha': 0.001, 'hidden_layer_sizes': (200,), 'learning_rate_init': 0.01}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best hyper-parameters: {mlp_tuned.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO notes about what could go wrong (memory consumption)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "hpc_for_datascience_demos",
   "language": "python",
   "name": "hpc_for_datascience_demos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
